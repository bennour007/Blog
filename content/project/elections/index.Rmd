---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/
title: "Elections project"
subtitle: ""
summary: "I extract the general elections data of 2014 in Tunisia, and replicate the results."
authors: []
tags: []
categories: []
date: 2019-24-02T21:54:20+01:00
lastmod: 2020-10-07T21:54:20+01:00
featured: false
draft: false
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: "Do we really need politicians, wouldn't an AI take better decision and work more efficiently than thouse monkeys? -Monkey Parliament, 2009"
  focal_point: ""
  preview_only: false
projects: []
editor_options: 
  chunk_output_type: console
---



As you may probably read in my blog, it's been a while now since I decided to see how the elections work and how a change in the voting system in tunisia may yield a tremendous change. 

At first I wasn't really overwhelmed by the process nor the work that needs to be done it self, however, the further I dive into some technical issues with my code, the more I realize *THIS SUCKS BIG TIME*.

I mean honestly, most of the problems I ran into were related to low quality data. Anyways, crying over the incompetence of isie data mangers won't change anything now.

Basically what took me too long was the fact that I was really confused in this project with R, relearning python and cleaning the rust out of my memory was really time consuming, even though I still need to do lots of work in order to upgrade my coding skills and algorithmic thinking, in addition some tweaks may be needed to make the code not only functional the way it is now, but also, elegant and optimal.

Now that I am more comfortable in the pythonic world of dynamism and ease, *THE COMMUNITY REALLY NEEDS TO FIND A WAY TO MIMIC RMD*. while this entire website is written in Rmd with Rstudio, I haven't come cross any reporting tool as elegant, and pertinent as Rmd and the knitr package in R. 

In what follows we will discuss some functionalities, some methodology and define few concepts for the reader who has no experience in the given matter.

I will not show all the code I used in this report however it will be [here](https://github.com/bennour007/elections) in my rep, for those who are going to check it out please leave me a feedback.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(tidyverse)
library(knitr)
library(reticulate)
use_condaenv('parmesan')
```

```{python include=FALSE}
import glob
import os
import pandas as pd 
import numpy as np
```
I will be dividing the work into phases, each phase will be focusing on a specific task over the data.

### Defining the files directory and paths
This is important for the Importing phase to loop on them when we need to access all the files and get all the names.

```{python include=FALSE}
dirs = glob.glob('/home/hsin/projects/elections/super_final_data/*.csv')
```


```{python include=FALSE}
fnames = os.listdir('/home/hsin/projects/elections/super_final_data')
names = [os.path.splitext(fnames[i])[0] for i in range(27)]
```

### Phase : Importation

Import the files with pandas in a dictionary to loop on in the analysis

###### we can also think about importing the data from the github repo, further preprocessing is needed if done. 


```{python include=FALSE}
dfs = {d: pd.read_csv(d) for d in dirs}
dfs = dict(zip(names, list(dfs.values())))
```

### Phase : Create a preperation function

We Have to prepare the data in 'dfs' to get the total votes for each list,

```{python}
# this function takes the dataframe sums row wise for each candidate 
# and return list name and the total votes
def prep(df):
    # act on the data frame and process it 
    df_0 = pd.concat([pd.DataFrame({'sumv':np.sum(df, axis=1)}), df['list']], axis = 1)
    return df_0
```

### Phase: Define and prepare  Hare quota arguments
Hare quota is the number of all votes in given city divided by the number of seats for that city. 
Based on the HQ we will create a table where we have:

  - electoral quota for each list: Q = 1 means list gets 1 seat etc.
  - seats collected fully by the votes quota, quota seats: QS.
  - remains R from the quota: votes who didn't got any seats to the list.
  - percentage P of the votes of the list from all votes.


```{python}
def hare(df, s):
    #total votes:
    ts = np.sum(df.sumv, axis = 0)
    #hare quota:
    hq = np.round(ts/s,decimals=3)
    #hare quota per list
    df['q'] = df.sumv/hq
    #quota seats
    df['qseats'] = np.fix(df.q)
    #remains
    df['r'] = df.q - df.qseats
    #percentage
    df['p'] = df.sumv/ts
    #sort the values with the highest remains first
    df = df.sort_values('r', ascending = False)
    return df
```

```{python include=FALSE}
tmp = hare(prep(dfs['sousse']), 10).head()
```
This is the result in Sousse:

```{r}
py$tmp %>% kable
```


### Phase : Prepare and perform computations for seats allocation

In this phase we will implement the largest remains allocation method for a given dataset. We will also give the opportunity to assign a minimum percentage of representation for lists to be accorded the remained seats. 
For each list sorted with regard to it's remains, and satisfying the condition on the percentage, we add a seat, until all lists are given one, if more seats are still not allocated we iterate again with the same order until we have none, or until the first condition is met and we repeat.


```{python}
def seats(df, s, p):
    df = df[df.p > p].reset_index()
    rs = np.int32(s - np.sum(df.qseats))
    for i in range(rs):
        df.qseats[i] = df.qseats[i] + 1
    return df[df.qseats > 0]
```

### Phase : Combine all processing and computations

For future ease of use, testing, and debugging, it is convenient to create a function that combine all of the above. 
Let's call it results().


```{python}
def results(df, s, p):
    return seats(hare(prep(df), s), s, p)
```


```{python include=FALSE}
tmp = results(dfs['sousse'], 10, 0)
```
here are the results in sousse

```{r echo=FALSE}
py$tmp %>% kable()
```

### Phase : Get data on seats for each region
Using data from the wikipedia article on regional dispatching of parliamentary seats in Tunisia,

[link]('https://ar.wikipedia.org/wiki/%D9%82%D8%A7%D8%A6%D9%85%D8%A9_%D8%A7%D9%84%D8%AF%D9%88%D8%A7%D8%A6%D8%B1_%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%AE%D8%A7%D8%A8%D9%8A%D8%A9_%D9%81%D9%8A_%D8%AA%D9%88%D9%86%D8%B3#%D8%A7%D9%84%D8%AF%D9%88%D8%A7%D8%A6%D8%B1_%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%AE%D8%A7%D8%A8%D9%8A%D8%A9_%D8%AF%D8%A7%D8%AE%D9%84_%D8%AA%D9%88%D9%86%D8%B3').

Ofcourse we will not be needing all the page, only the table, the region, and seats associated.


```{python include=FALSE}
sieges = pd.read_html('https://ar.wikipedia.org/wiki/%D9%82%D8%A7%D8%A6%D9%85%D8%A9_%D8%A7%D9%84%D8%AF%D9%88%D8%A7%D8%A6%D8%B1_%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%AE%D8%A7%D8%A8%D9%8A%D8%A9_%D9%81%D9%8A_%D8%AA%D9%88%D9%86%D8%B3#%D8%A7%D9%84%D8%AF%D9%88%D8%A7%D8%A6%D8%B1_%D8%A7%D9%84%D8%A7%D9%86%D8%AA%D8%AE%D8%A7%D8%A8%D9%8A%D8%A9_%D8%AF%D8%A7%D8%AE%D9%84_%D8%AA%D9%88%D9%86%D8%B3')[1]
```


```{python include=FALSE}
tmp = sieges.head()
```

```{r echo=FALSE}
py$tmp %>% kable()
```

```{python include=FALSE}
sieges = sieges.iloc[:,[1,3]]
```

```{python include=FALSE}
# we will reorder the names, and fix the arrangement with regard to the seats in the table above
names.sort()
# this order vector will be of the utmost importance in later stages
order = [0,1,2,3,4,5,6,7,8,9,12,10,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26]
namesnew = [names[i] for i in order]
```


```{python include=FALSE}
sieges['gov'] = namesnew
sieges = sieges.iloc[:,1:].rename(columns = {'المقاعد' : 'seats'})
```
Because of the confusion between arabic letters and latin letters python orders them in a different manner so we needed to reorder them again in a consistent manner between arabic and latin letters.

```{r echo=FALSE}
py$sieges %>% kable()
```


```{python include=FALSE}
s = dict(zip(namesnew, list(sieges.seats)))
```

### Phase : Constructing the results 

We will now use the table above, to loop for each region, it's associated dataset in 'dfs', pass it to the functions one by one , using also the corresponding number of seats for each specified in the column seats. 

We will associate the results into a dictionary we will call it 'fr', for final results, each key will be looped on as the name of the data set, and each value will be resulted dataset from the results function of the looped upon dfs dictionary.

In order to do this iteration, We will need to reorder the arrangement of names on which we created the 'dfs' dictionary, therefore, we need to reimport the data again in a proper manner.


```{python include=FALSE}
dirs.sort()
dirsnew = [dirs[i] for i in order]
```


```{python include=FALSE}
dfs = {d: pd.read_csv(d) for d in dirsnew}
dfs = dict(zip(namesnew, list(dfs.values())))
```


```{python include=FALSE}
res = {n : results(dfs[n], s[n], 0) for n in namesnew }
```


### Phase : Cleaning the names of the lists.
In this section I discovered That some names in arabic have been written in a terrible manner, this could create inconsistent results later on in the plotting, therefore we need to make the names of the lists that went to the parliament are clean.


```{python include=FALSE}
winners = ['قائمة حركة نداء تونس',
           'قائمة حزب حركة النهضة',
           'قائمة حزب الاتحاد الوطني الحر',
           'قائمة الجبهة الشعبية',
           'قائمة حزب التيار الديمقراطي',
           'قائمة حزب التحالف',
           'قائمة حزب المؤتمر من أجل الجمهورية',
           'القائمة المستقلة الإقلاع',
           'قائمة حزب صوت الفلاحين',
           'قائمة  تيار المحبة',
           'قائمة حركة الشعب',
           'قائمة حزب آفاق تونس',
           'قائمة الجبهة الوطنية للإنقاذ',
           'قائمة الوفاء لمشروع الشهيد',
           'قائمة حزب المبادرة',
           'قائمة المجد الجريد' ]
tmp = pd.DataFrame(winners)
```

```{r echo=FALSE}
py$tmp %>% kable()
```

We also needed to clean up some issues in the lists names like spaces, underscores, and more confusion because of arabic letters.

```{python include=FALSE}
res[namesnew[17]].list = [winners[i] for i in [1,3,4,0]]
res[namesnew[4]].list = [winners[i] for i in [1,2,6,0]]
res[namesnew[25]].list = [winners[i] for i in [1,0,11]]
res[namesnew[24]].list = [winners[i] for i in [0,4,3,1]]
res[namesnew[23]].list = [winners[i] for i in [15,0,2,1]]
res[namesnew[19]].list = [winners[i] for i in [9,3,1,12,13,0]]
res[namesnew[15]].list = [winners[i] for i in [0,1,11]]
res[namesnew[14]].list = [winners[i] for i in [1,11,3,0]]
res[namesnew[11]].list = [winners[i] for i in [0,3,2,1]]
res[namesnew[8]].list = [winners[i] for i in [1,3,2,6,0]]
res[namesnew[3]].list = [winners[i] for i in [1,5,2,0]]
res[namesnew[2]].list = [winners[i] for i in [0,1,2,3,4]]
```


```{python include=FALSE}
pure = [res[i][['list','qseats']] for i in namesnew]
```


```{python include=FALSE}
w = pd.concat(pure)
l = w['list'].drop_duplicates()
```


```{python include=FALSE}
order = {i : w[w['list'] == i] for i in l}
```


```{python include=FALSE}
order2 = {i : order[i].drop('list',axis = 1).sum() for i in l}
win = pd.DataFrame(order2).transpose().reset_index()
win.columns = ['list','seats']
```


```{python eval=FALSE, include=FALSE}
win.to_csv("/home/hsin/projects/elections/seats.csv")
```


## The results : a simple graphic

*I only used mainland data here we haven't integrated abroad citizens votes*

```{r}
tmp <- py$win
tmp %>% 
  mutate(list = fct_reorder(list, seats)) %>%
  ggplot(aes(x= seats, y = list)) +
  geom_col(fill = "sky blue") +
  geom_text(aes(label = tmp$seats), hjust = -.2, color = "grey") +
  theme_light()
```

## Summary and conclusion:


I have used both python and R in order to achieve this, technically using them both is the ideal. The technical issues I faced during this little project, which I will keep updating and improving, are mainly related to the bad data quality that the ISIE is sharing with the public, the problem is that this is official legal and approved-by-the-court public data, the least that (the institution with the biggest budget in the entire country) can do is provide data with quality and clear standards. 
Putting all of this aside, I will be developing a shiny app to further demonstrate the effect of the percentage quota on the results really shortly. 
This was fun, looking forward for your feedback.

TO BE CONTINUED.
